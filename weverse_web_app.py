import streamlit as st
import json, time, re, os, requests, io, zipfile
import pandas as pd
from datetime import datetime
from playwright.sync_api import sync_playwright

# --- é é¢è¨­å®š ---
st.set_page_config(page_title="Weverse Web æœé›†å™¨", page_icon="ğŸ›ï¸")
st.title("ğŸ›ï¸ Weverse Shop å•†å“æœé›†åŠ©æ‰‹")

# --- åˆå§‹åŒ– Session State (é˜²æ­¢ä¸‹è¼‰é‡æ•´) ---
if 'data_ready' not in st.session_state:
    st.session_state.data_ready = False
    st.session_state.excel_data = None
    st.session_state.zip_data = None
    st.session_state.title = ""
    st.session_state.currency = ""

# --- æ ¸å¿ƒæœé›†å‡½å¼ ---
def fetch_weverse_data(category_url):
    # 1. æ ¹æ“šç¶²å€åµæ¸¬è²¨å¹£ä¸¦é¸æ“‡å°æ‡‰çš„ JSON
    if "KRW" in category_url:
        auth_file = "weverse_env_KR.json"
        st.info("ğŸ‡°ğŸ‡· åµæ¸¬åˆ°éŸ“åœ‹é¤¨åˆ¥ï¼Œæ­£åœ¨è¼‰å…¥éŸ“åœ‹ç’°å¢ƒè¨­å®š...")
    elif "JPY" in category_url:
        auth_file = "weverse_env_JP.json"
        st.info("ğŸ‡¯ğŸ‡µ åµæ¸¬åˆ°æ—¥æœ¬é¤¨åˆ¥ï¼Œæ­£åœ¨è¼‰å…¥æ—¥æœ¬ç’°å¢ƒè¨­å®š...")
    else:
        st.error("âŒ ç„¡æ³•å¾ç¶²å€è¾¨è­˜è²¨å¹£é¡å‹ (éœ€åŒ…å« KRW æˆ– JPY)")
        return None, None, None, None

    # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
    if not os.path.exists(auth_file):
        st.error(f"âŒ æ‰¾ä¸åˆ°è¨­å®šæª”: {auth_file}")
        return None, None, None, None

    with sync_playwright() as p:
        # é›²ç«¯ç’°å¢ƒå®‰è£èˆ‡å•Ÿå‹•
        os.system("playwright install chromium")
        browser = p.chromium.launch(headless=True)
        context = browser.new_context(storage_state=auth_file)
        page = context.new_page()

        # æå–åƒæ•¸
        url_match = re.search(r'artists/(\d+)/', category_url)
        artist_id = url_match.group(1) if url_match else "7"
        current_currency = "KRW" if "KRW" in category_url else "JPY"

        page.goto(category_url)
        page.wait_for_load_state("domcontentloaded")
        
        # æ¨™é¡Œè™•ç†ï¼šä¿ç•™ '-' ä¹‹å¾Œçš„å…§å®¹
        full_title = page.title().replace("Weverse Shop :", "").strip()
        clean_title = full_title.split('-')[-1].strip() if '-' in full_title else full_title
        safe_title = re.sub(r'[\\/*?:"<>|]', "", clean_title).strip().replace(" ", "_")

        # ç²å–å•†å“æ¸…å–®
        page.wait_for_selector("#__NEXT_DATA__", state="attached")
        cat_json = json.loads(page.locator("#__NEXT_DATA__").inner_text())
        queries = cat_json['props']['pageProps']['$dehydratedState']['queries']
        basic_products = []
        for q in queries:
            if 'productCards' in q.get('state', {}).get('data', {}):
                basic_products = q['state']['data']['productCards']
                break

        rows = []
        image_list = []
        progress_bar = st.progress(0)
        status_text = st.empty()

        for i, item in enumerate(basic_products):
            p_name = item['name']
            safe_p_name = re.sub(r'[\\/*?:"<>|]', "", p_name).strip().replace(" ", "_")
            detail_url = f"https://shop.weverse.io/zh-cn/shop/{current_currency}/artists/{artist_id}/sales/{item['saleId']}"
            
            status_text.text(f"æ­£åœ¨è§£æ ({i+1}/{len(basic_products)}): {p_name}")
            progress_bar.progress((i + 1) / len(basic_products))

            try:
                page.goto(detail_url)
                page.wait_for_selector("#__NEXT_DATA__", state="attached")
                prod_json = json.loads(page.locator("#__NEXT_DATA__").inner_text())
                prod_queries = prod_json['props']['pageProps']['$dehydratedState']['queries']
                
                detail = None
                for q in prod_queries:
                    d = q.get('state', {}).get('data', {})
                    if isinstance(d, dict) and str(d.get('saleId')) == str(item['saleId']):
                        detail = d
                        break
                
                if detail:
                    thumb_list = detail.get("thumbnailImageUrls", [])
                    img_url = thumb_list[0] if thumb_list else ""
                    
                    if img_url:
                        try:
                            img_res = requests.get(img_url, timeout=5)
                            if img_res.status_code == 200:
                                image_list.append((f"{safe_p_name}.jpg", img_res.content))
                        except: pass

                    limit = detail.get("goodsOrderLimit", {}).get("maxOrderQuantity", "N/A")
                    opts = detail.get("options", []) or detail.get("option", {}).get("options", [])
                    
                    if not opts:
                        rows.append([p_name, detail_url, img_url, "å–®ç¨®é¡", detail.get("price"), limit])
                    else:
                        for idx, opt in enumerate(opts):
                            spec = opt.get("saleOptionName")
                            price = opt.get("optionSalePrice")
                            opt_limit = opt.get("optionOrderLimit", {}).get("maxOrderQuantity")
                            row_limit = opt_limit if opt_limit else limit
                            if idx == 0:
                                rows.append([p_name, detail_url, img_url, spec, price, row_limit])
                            else:
                                rows.append(["", "", "", spec, price, ""])
            except: pass
            time.sleep(0.1)

        browser.close()
        return rows, image_list, safe_title, current_currency

# --- UI ä»‹é¢ ---
target_url = st.text_input("ğŸ”— è«‹è²¼ä¸Šé¤¨åˆ¥ç¶²å€:", placeholder="https://shop.weverse.io/...")

if st.button("ğŸš€ é–‹å§‹æ“·å–æ•¸æ“š"):
    if target_url:
        with st.spinner('çˆ¬èŸ²é‹ä½œä¸­ï¼Œè«‹ç¨å€™...'):
            rows, images, title, currency = fetch_weverse_data(target_url)
            if rows:
                # è™•ç† Excel ç·©å­˜
                df = pd.DataFrame(rows, columns=["å•†å“åç¨±", "ç¶²å€url", "ç…§ç‰‡url", "è¦æ ¼/ç¨®é¡", "åƒ¹æ ¼", "è³¼è²·ä¸Šé™"])
                excel_buffer = io.BytesIO()
                df.to_excel(excel_buffer, index=False)
                
                # è™•ç† ZIP ç·©å­˜
                zip_buffer = io.BytesIO()
                with zipfile.ZipFile(zip_buffer, "a", zipfile.ZIP_DEFLATED, False) as zip_file:
                    for img_name, img_content in images:
                        zip_file.writestr(img_name, img_content)

                st.session_state.excel_data = excel_buffer.getvalue()
                st.session_state.zip_data = zip_buffer.getvalue()
                st.session_state.title = title
                st.session_state.currency = currency
                st.session_state.data_ready = True
                st.success("âœ… æ“·å–å®Œæˆï¼")

if st.session_state.data_ready:
    st.divider()
    st.subheader(f"ğŸ“‚ ä¸‹è¼‰å€: {st.session_state.title}")
    col1, col2 = st.columns(2)
    with col1:
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰ Excel å ±è¡¨",
            data=st.session_state.excel_data,
            file_name=f"{st.session_state.title}_{st.session_state.currency}.xlsx",
            mime="application/vnd.ms-excel"
        )
    with col2:
        st.download_button(
            label="ğŸ–¼ï¸ ä¸‹è¼‰å…¨éƒ¨åœ–ç‰‡ (ZIP)",
            data=st.session_state.zip_data,
            file_name=f"{st.session_state.title}_images.zip",
            mime="application/zip"
        )